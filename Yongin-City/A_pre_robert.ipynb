{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3949,
     "status": "ok",
     "timestamp": 1697558103235,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "C99faxmffNrI",
    "outputId": "87823096-cb0a-4a25-fbcc-6bcc757c83c9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32823,
     "status": "ok",
     "timestamp": 1697558136054,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "fd7S48KIfcBv",
    "outputId": "48c09d1b-3a4b-4a01-b326-717873fbde01"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install symspellpy\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "#!pip install emot\n",
    "#pip install contractions\n",
    "#!pip -q install evaluate\n",
    "#!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtdxwEua_UVU"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1697566952796,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "4cDoeV_afZA3",
    "outputId": "012df836-3499-4a42-deaa-98ba13de3619"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "#from emot.emo_unicode import UNICODE_EMOJI\n",
    "#from emot.emo_unicode import EMOTICONS_EMO\n",
    "import nltk\n",
    "import spacy\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1697566051057,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "MOeifge8fXop",
    "outputId": "80e6048f-caf2-455e-cc95-57a79f10fe8d"
   },
   "outputs": [],
   "source": [
    "# 런타임 확인\n",
    "n_devices = torch.cuda.device_count()\n",
    "print(n_devices)\n",
    "\n",
    "for i in range(n_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1697567321625,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "slqWoA6ofeev"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1697567321626,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "cMaAWR0HZ43L",
    "outputId": "e746888b-be10-41c4-e3a1-46dea306d985"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cM_asmAQ55U1"
   },
   "source": [
    "### preprocessing1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1697567439712,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "RKD46aOa0i5s"
   },
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(tweet):\n",
    "    tweets = \" \".join(filter(lambda x: x[0]!= '@' , tweet.split()))\n",
    "    tweets = re.sub('[^a-zA-Z]', ' ', tweets)\n",
    "    tweets = tweets.lower()\n",
    "    tweets = tweets.split()\n",
    "    tweets = [word for word in tweets if not word in set(stopwords.words('english'))]\n",
    "    tweets = [lemma.lemmatize(word) for word in tweets]\n",
    "    tweets = \" \".join(tweets)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "executionInfo": {
     "elapsed": 188338,
     "status": "ok",
     "timestamp": 1697567628027,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "Ero3l-my0pNp"
   },
   "outputs": [],
   "source": [
    "train['text'] = train.text.apply(clean_text)\n",
    "test['text'] = test.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1697567644397,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "opNqgrFy2Fe7",
    "outputId": "49a5a9a8-044b-4cca-aaec-e7b2fc676f24"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1697567644998,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "J-_HAjX56QXW",
    "outputId": "c0300c45-8631-4493-c6a3-b339268ad3cd"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1697566577854,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "0TTBrPDa2ftF"
   },
   "outputs": [],
   "source": [
    "def extract_hashtag(tweet):\n",
    "    tweets = \" \".join(filter(lambda x: x[0]== '#', tweet.split()))\n",
    "    tweets = re.sub('[^a-zA-Z]',' ',  tweets)\n",
    "    tweets = tweets.lower()\n",
    "    tweets = [lemma.lemmatize(word) for word in tweets]\n",
    "    tweets = \"\".join(tweets)\n",
    "    return tweets\n",
    "\n",
    "train['word_with_hashtag'] = train.text.apply(extract_hashtag)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1697567223123,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "DmzB1i8H46nF",
    "outputId": "430f8e8a-b9e4-4e57-819a-d85496831809"
   },
   "outputs": [],
   "source": [
    "print(train.loc[11920].text)\n",
    "print(train.loc[11920].clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIRGGSzZ5PA1"
   },
   "outputs": [],
   "source": [
    "train = train.drop([\"tweet\",\"word_with_hashtag\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7GdklVh23Xw"
   },
   "outputs": [],
   "source": [
    "racist_sexist_hashtag = FreqDist(list(\" \".join(train[train['sentiment']==1]['word_with_hashtag']).split())).most_common(15)\n",
    "racist_sexist_data = pd.DataFrame(racist_sexist_hashtag, columns=['words', 'frequency'])\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.barplot(x='words',y=\"frequency\" ,data=racist_sexist_data,color=\"deepskyblue\")\n",
    "\n",
    "plt.title('Racist and Sexist Words with Hashtags\\n',fontsize=20,color=\"darkorange\")\n",
    "plt.xlabel(\"\\nWords\",fontsize=20,color=\"darkorange\")\n",
    "plt.ylabel(\"Frequency\\n\",fontsize=20,color=\"darkorange\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pljoUZQB5-tZ"
   },
   "source": [
    "### preprocessing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 4612,
     "status": "ok",
     "timestamp": 1697559076200,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "RlSejdIgffLh"
   },
   "outputs": [],
   "source": [
    "##CUSTOM DEFINED FUNCTIONS TO CLEAN THE TWEETS\n",
    "\n",
    "#Remove punctuations, links, mentions and \\r\\n new line characters\n",
    "def clean_symbols(tweet):\n",
    "    # Remove @ and # symbols from the tweet\n",
    "    new_tweet = re.sub(r'[@#]', '', tweet)\n",
    "    new_tweet = re.sub(r'’', '\\'', new_tweet)\n",
    "    new_tweet = re.sub(r'\\d', '', new_tweet)\n",
    "    new_tweet = re.sub(r'-', ' ', new_tweet)\n",
    "    return new_tweet.strip()\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    text = re.sub(r'\\B@\\w+', '', text)\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    #text = re.sub(r'(?:\\@|https?\\://)\\S+', '', text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)\n",
    "\n",
    "#축약어 사전\n",
    "contraction_mapping = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"I would\",\n",
    "    \"i'd've\": \"I would have\",\n",
    "    \"i'll\": \"I will\",\n",
    "    \"i'll've\": \"I will have\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"this's\": \"this is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"that'll\": \"that will\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"yr\": \"year\"\n",
    "}\n",
    "\n",
    "'''\n",
    "def expand_contractions(text, contraction_mapping=contraction_mapping):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        if first_char.isupper():\n",
    "            expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "            expanded_contraction = expanded_contraction.capitalize()\n",
    "        else:\n",
    "            expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    return expanded_text\n",
    "'''\n",
    "\n",
    "def expand_contractions(text):\n",
    "    # 단어 별로 축약된 형태를 정규식을 사용하여 대응 규칙을 적용\n",
    "    contraction_patterns = [(rf\"{key}\", value) for key, value in contraction_mapping.items()]\n",
    "\n",
    "    for pattern, replacement in contraction_patterns:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "#Lemmatization1\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text1(text):\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "#Lemmatization2\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 단어를 기본형으로 변환하는 함수\n",
    "def lemmatize_text2(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "#Spelling Correction\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = \"/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/frequency_dictionary_en_82_765.txt\"\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "def correct_spelling_symspell(text):\n",
    "    words = [\n",
    "        sym_spell.lookup(\n",
    "            word,\n",
    "            Verbosity.CLOSEST,\n",
    "            max_edit_distance=2,\n",
    "            include_unknown=True\n",
    "            )[0].term\n",
    "        for word in text.split()]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "#Correcting Compound Words\n",
    "\n",
    "bigram_path = \"/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/frequency_bigramdictionary_en_243_342.txt\"\n",
    "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "def correct_compound(text):\n",
    "    words = [\n",
    "        sym_spell.lookup_compound(\n",
    "            word,\n",
    "            max_edit_distance=2\n",
    "            )[0].term\n",
    "        for word in text.split()]\n",
    "    text = \" \".join(words)\n",
    "    #text = re.sub(r'\\b(a|of)\\b', '', text) #불용어 a와 of 제거\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "executionInfo": {
     "elapsed": 1000768,
     "status": "ok",
     "timestamp": 1697560095370,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "oF9qfIfBgdGD"
   },
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].apply(clean_symbols)\n",
    "test[\"text\"] = test[\"text\"].apply(clean_symbols)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(strip_all_entities)\n",
    "test[\"text\"] = test[\"text\"].apply(strip_all_entities)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(filter_chars)\n",
    "test[\"text\"] = test[\"text\"].apply(filter_chars)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(remove_mult_spaces)\n",
    "test[\"text\"] = test[\"text\"].apply(remove_mult_spaces)\n",
    "\n",
    "#Lower Casing\n",
    "train[\"text\"] = train[\"text\"].str.lower()\n",
    "test[\"text\"] = test[\"text\"].str.lower()\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(expand_contractions)\n",
    "test[\"text\"] = test[\"text\"].apply(expand_contractions)\n",
    "\n",
    "#lemmatization\n",
    "train[\"text\"] = train[\"text\"].apply(lemmatize_text2)\n",
    "test[\"text\"] = test[\"text\"].apply(lemmatize_text2)\n",
    "\n",
    "#Lower Casing\n",
    "train[\"text\"] = train[\"text\"].str.lower()\n",
    "test[\"text\"] = test[\"text\"].str.lower()\n",
    "\n",
    "#spelling correction\n",
    "train[\"text\"] = train[\"text\"].apply(correct_spelling_symspell)\n",
    "test[\"text\"] = test[\"text\"].apply(correct_spelling_symspell)\n",
    "\n",
    "#correcting compound words\n",
    "train[\"text\"] = train[\"text\"].apply(correct_compound)\n",
    "test[\"text\"] = test[\"text\"].apply(correct_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1697560096219,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "rdoAFnZLxDPl"
   },
   "outputs": [],
   "source": [
    "# 두 칸 이상의 빈칸을 한칸의 빈칸으로 변환\n",
    "train['text'] = train['text'].str.replace(\"\\s+\", \" \", regex=True)\n",
    "test['text'] = test['text'].str.replace(\"\\s+\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1697560096220,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "3gTOiR08h-XK",
    "outputId": "5e68bc8d-2e76-4a08-bbf0-519d7cf9dcea"
   },
   "outputs": [],
   "source": [
    "t = train.loc[20000].text\n",
    "\n",
    "print(t)\n",
    "print()\n",
    "print(1, clean_symbols(t))\n",
    "print(2, strip_all_entities(t))\n",
    "print(3, filter_chars(t))\n",
    "print(4, remove_mult_spaces(t))\n",
    "print(5, expand_contractions(t))\n",
    "print(6, lemmatize_text1(t))\n",
    "print(7, lemmatize_text2(t))\n",
    "print(8, correct_spelling_symspell(t))\n",
    "print(9, correct_compound(t))\n",
    "print()\n",
    "\n",
    "t = correct_compound(correct_spelling_symspell(lemmatize_text2(expand_contractions(remove_mult_spaces(filter_chars(strip_all_entities(clean_symbols(t))))))))\n",
    "print('final:', t)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1697560131146,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "RVgY4UuaiE99",
    "outputId": "51658d48-4d0d-4b0b-815c-3e15744c1d4e"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1697560138455,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "HHSQ9JcleAJX",
    "outputId": "b19070cf-150c-481d-96ff-bc366c6a4e72"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1697567665518,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "biVYJpR1lOcF"
   },
   "outputs": [],
   "source": [
    "train.to_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/trans_pre_train2.csv', index=False)\n",
    "test.to_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/trans_pre_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPIUoZJEGcpR"
   },
   "source": [
    "# Robert 1 (best: 83%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1697567720065,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "RUlhiCWLX9sg"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/trans_pre_train2.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/trans_pre_test2.csv')\n",
    "\n",
    "data = data.dropna()\n",
    "test['text'].fillna('text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1697567730717,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "P5ESR41peWJy",
    "outputId": "ed4a012e-ba12-456f-f8fd-70b3bbc88062"
   },
   "outputs": [],
   "source": [
    "texts = data['text'].tolist()\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 946884,
     "status": "ok",
     "timestamp": 1697568695871,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "hGrTiW2HHJ3s",
    "outputId": "93624d05-b4b4-4b7f-df41-dc3722096d76"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "texts = data['text'].tolist()\n",
    "sentiments = data['sentiment'].tolist()\n",
    "\n",
    "\n",
    "# ROBERTa 토크나이저 초기화\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# 데이터 토큰화\n",
    "encoded_texts = tokenizer(texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "input_ids = encoded_texts['input_ids']\n",
    "attention_masks = encoded_texts['attention_mask']\n",
    "\n",
    "# 라벨 매핑 (e.g., {'positive': 0, 'neutral': 1, 'negative': 2})\n",
    "label_mapping = {label: i for i, label in enumerate(set(sentiments))}\n",
    "labels = [label_mapping[s] for s in sentiments]\n",
    "\n",
    "# 텐서로 변환\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 데이터셋 분할\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "# 모델 초기화\n",
    "num_labels = len(label_mapping)\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저 및 스케줄러 설정\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
    "\n",
    "# 훈련 함수\n",
    "def train(model, iterator, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(iterator)\n",
    "\n",
    "# 검증 함수\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iterator):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "    return total_loss / len(iterator)\n",
    "\n",
    "# 훈련 및 검증\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, optimizer, scheduler)\n",
    "    val_loss = evaluate(model, val_dataloader)\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572620,
     "status": "ok",
     "timestamp": 1697564243588,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "Ck1Ve64yYSic",
    "outputId": "1ca055b4-b22f-4a2c-a07f-198d684fed2a"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 토큰화\n",
    "test_texts = test['text'].tolist()\n",
    "encoded_test_texts = tokenizer(test_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "input_ids_test = encoded_test_texts['input_ids']\n",
    "attention_masks_test = encoded_test_texts['attention_mask']\n",
    "\n",
    "# 텐서로 변환\n",
    "input_ids_test = torch.tensor(input_ids_test)\n",
    "attention_masks_test = torch.tensor(attention_masks_test)\n",
    "\n",
    "# 배치 크기 설정\n",
    "batch_size = 32\n",
    "\n",
    "# 테스트 데이터 로더 생성\n",
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# 모델 평가 함수\n",
    "def predict_sentiment(model, iterator):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iterator):\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            predictions.extend(predicted.tolist())\n",
    "    return predictions\n",
    "\n",
    "# 감정 예측\n",
    "test_predictions = predict_sentiment(model, test_dataloader)\n",
    "\n",
    "# 예측 결과를 데이터프레임에 추가\n",
    "#test['predicted_sentiment'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1697564800853,
     "user": {
      "displayName": "‍한승윤[재학 / 컴퓨터.전자시스템공학전공]",
      "userId": "08967695426292389766"
     },
     "user_tz": -540
    },
    "id": "MYexIoZ4ayTb"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test[\"id\"], \"sentiment\": test_predictions})\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "submission.to_csv('/content/drive/MyDrive/Colab Notebooks/Yongin-city/csv파일/roberta_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy8-Y7NwrW5C"
   },
   "source": [
    "# Robert 2(73%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qegJxMyrDKuL"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/용인시 SW 해커톤/trans_pre_train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/용인시 SW 해커톤/trans_pre_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161,
     "referenced_widgets": [
      "5f29ba2e6f1947e8a311795502efdf62",
      "a6a84570a23a4402b8752a7273bcf74d",
      "19adb718e54f4dcf85ac80bdff01cf39",
      "5305d3c7f98349bbbcbe2f1b49de1406",
      "cf51c83fe2f74c55817997b7392e9fad",
      "98775a981ba141308a7ebbc936bc9908",
      "3a76f7187c91457ea964c88fa11533d6",
      "62b4330db7cf429ca00e989be345308e",
      "ef82c7cfab5f4505b0a8f8e180fce20d",
      "576d60242a8a44098de19cd5693aba8f",
      "d48c3de0acf04ae3979318671f861bf0"
     ]
    },
    "id": "11Y2LvTHrQDf",
    "outputId": "9c301727-4bb3-43ac-eed9-6c1689696f2f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx][\"text\"]\n",
    "        label = self.data.iloc[idx][\"sentiment\"]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device, loss_function):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_function(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def evaluate(model, data_loader, device, loss_function):\n",
    "    model = model.eval()\n",
    "    labels_all = []\n",
    "    predictions_all = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_function(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            labels_all.extend(labels.cpu().numpy())\n",
    "            predictions_all.extend(preds.cpu().numpy())\n",
    "\n",
    "    loss_mean = np.mean(losses)\n",
    "    f1_macro = f1_score(labels_all, predictions_all, average='macro')\n",
    "    return loss_mean, f1_macro\n",
    "\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 10\n",
    "batch_size = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"sentiment\"], random_state=42)\n",
    "\n",
    "train_dataset = NewsDataset(train_data, tokenizer, max_length=512)\n",
    "val_dataset = NewsDataset(val_data, tokenizer, max_length=512)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == \"sum\":\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "# Instantiate the FocalLoss\n",
    "loss_function = FocalLoss(alpha=1.0, gamma=2.0, reduction=\"mean\").to(device)\n",
    "\n",
    "best_f1_macro = 0\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, loss_function)\n",
    "    print(f\"Train loss: {train_loss}\")\n",
    "\n",
    "    val_loss, val_f1_macro = evaluate(model, val_loader, device, loss_function)\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    print(f\"Validation F1 Macro: {val_f1_macro}\")\n",
    "\n",
    "    if val_f1_macro > best_f1_macro:\n",
    "        print(\"F1 Macro score improved. Saving the model.\")\n",
    "        best_f1_macro = val_f1_macro\n",
    "        torch.save(model.state_dict(), \"best_roberta_large_model.bin\")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_roberta_large_model.bin\"))\n",
    "\n",
    "class TestNewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx][\"text\"]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tIS6lvFZMVm"
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_roberta_large_model.bin\"))\n",
    "\n",
    "class TestNewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx][\"text\"]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxvDc49zZu8L"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the test dataset\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_dataset = TestNewsDataset(test_data, tokenizer, max_length=512)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = predict(model, test_loader, device)\n",
    "\n",
    "# Create submission DataFrame and save it as a CSV file\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"], \"label\": predictions})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Inference completed. The submission.csv file has been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KuO5FJiXrMtT",
    "outputId": "2fa3f98e-75f9-42b5-ccee-780be92fb815"
   },
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "\n",
    "nan_count = train.isna().sum().sum()\n",
    "\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c-HIqwmKKL7"
   },
   "source": [
    "# Robert 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "f9W3ENYoL8J-",
    "outputId": "7b61de3c-b349-41d6-80b6-c69d03ed8d21"
   },
   "outputs": [],
   "source": [
    "#general purpose packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#data processing\n",
    "import re, string\n",
    "import nltk\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#transformers\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertModel\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import TFRobertaModel\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertModel\n",
    "from transformers import XLNetTokenizerFast\n",
    "from transformers import TFXLNetModel\n",
    "from transformers import XLMTokenizer\n",
    "from transformers import TFXLMModel\n",
    "\n",
    "\n",
    "\n",
    "#keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#set seed for reproducibility\n",
    "seed=42\n",
    "\n",
    "#set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine()\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PLti6gdKJic"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/용인시 SW 해커톤/trans_pre_train.csv')\n",
    "df_test = pd.read_csv('/content/drive/MyDrive/용인시 SW 해커톤/trans_pre_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8KsG3NBoNeY4",
    "outputId": "f8da71fc-b81e-4ea5-d6e3-b747dd227139"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, AdamWeightDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "# 데이터 분할\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(list(df['text']), list(df['sentiment']), test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=64, return_tensors=\"pt\", padding='max_length')\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=64, return_tensors=\"pt\", padding='max_length')\n",
    "\n",
    "# Convert to tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))\n",
    "\n",
    "# Create a configuration for the model\n",
    "config = RobertaConfig.from_pretrained('roberta-base', num_labels=3)\n",
    "config.hidden_dropout_prob = 0.3\n",
    "config.attention_probs_dropout_prob = 0.3\n",
    "\n",
    "# Initialize the model with the configuration\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', config=config)\n",
    "\n",
    "# Compile the model using AdamW\n",
    "optimizer = AdamWeightDecay(learning_rate=5e-5)\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset.shuffle(1000).batch(32), validation_data=val_dataset.batch(32), epochs=8, batch_size=32, callbacks=[early_stopping, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZSks5OHMG2K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Fy8-Y7NwrW5C",
    "_c-HIqwmKKL7"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02e5406b32eb4fe5a8f16573e5f1a5d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c57100858b145d3b83c2b3ae831746e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16234cf4d0e64d55af7777c84c66f5ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "19adb718e54f4dcf85ac80bdff01cf39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62b4330db7cf429ca00e989be345308e",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef82c7cfab5f4505b0a8f8e180fce20d",
      "value": 498818054
     }
    },
    "2cb23edf7aa74c948d83fac0150fa265": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a76f7187c91457ea964c88fa11533d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d3522c812054037be2ccef97b6d925a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad33c5afaf47403f87cb749b91342727",
      "placeholder": "​",
      "style": "IPY_MODEL_d98563d8614f4bec8a995fc876a9247c",
      "value": " 400/400 [01:35&lt;00:00,  4.18it/s]"
     }
    },
    "4dfaadfd69fc4ea2b9c6736438e6be1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f865f94a1890414ba928c8f17c94e9c0",
       "IPY_MODEL_85ebe9dacdb747a9b0ad51524f2c7070",
       "IPY_MODEL_70eb92a2399046948fc713c16acc3dd7"
      ],
      "layout": "IPY_MODEL_2cb23edf7aa74c948d83fac0150fa265"
     }
    },
    "5305d3c7f98349bbbcbe2f1b49de1406": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_576d60242a8a44098de19cd5693aba8f",
      "placeholder": "​",
      "style": "IPY_MODEL_d48c3de0acf04ae3979318671f861bf0",
      "value": " 499M/499M [00:01&lt;00:00, 411MB/s]"
     }
    },
    "576d60242a8a44098de19cd5693aba8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c46b20be33b48d792582e0c113acb76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c57100858b145d3b83c2b3ae831746e",
      "placeholder": "​",
      "style": "IPY_MODEL_d86d013fff214d88aa962e0dcc016279",
      "value": "100%"
     }
    },
    "5f29ba2e6f1947e8a311795502efdf62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6a84570a23a4402b8752a7273bcf74d",
       "IPY_MODEL_19adb718e54f4dcf85ac80bdff01cf39",
       "IPY_MODEL_5305d3c7f98349bbbcbe2f1b49de1406"
      ],
      "layout": "IPY_MODEL_cf51c83fe2f74c55817997b7392e9fad"
     }
    },
    "62b4330db7cf429ca00e989be345308e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "643045b193654d998147d3d4a649c0e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70eb92a2399046948fc713c16acc3dd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_643045b193654d998147d3d4a649c0e5",
      "placeholder": "​",
      "style": "IPY_MODEL_02e5406b32eb4fe5a8f16573e5f1a5d5",
      "value": " 3600/3600 [44:02&lt;00:00,  1.40it/s]"
     }
    },
    "835ad884c65b49cfac06af8464c3285d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84497b15685d4fad9f43a8452575b44a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ebe9dacdb747a9b0ad51524f2c7070": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_835ad884c65b49cfac06af8464c3285d",
      "max": 3600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16234cf4d0e64d55af7777c84c66f5ef",
      "value": 3600
     }
    },
    "90f0ed23dd9049a2bf36bed9e5344226": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98775a981ba141308a7ebbc936bc9908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a84570a23a4402b8752a7273bcf74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98775a981ba141308a7ebbc936bc9908",
      "placeholder": "​",
      "style": "IPY_MODEL_3a76f7187c91457ea964c88fa11533d6",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "ad33c5afaf47403f87cb749b91342727": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b37354a8bbe74441b5fd5551b78f8b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0725b5427a645c9800b0d4c6a5d206c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e688e965fd394e2bab2faa90b9841882",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b37354a8bbe74441b5fd5551b78f8b74",
      "value": 400
     }
    },
    "cf51c83fe2f74c55817997b7392e9fad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d143a802a7484950808ce8eb67d96237": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c46b20be33b48d792582e0c113acb76",
       "IPY_MODEL_c0725b5427a645c9800b0d4c6a5d206c",
       "IPY_MODEL_3d3522c812054037be2ccef97b6d925a"
      ],
      "layout": "IPY_MODEL_84497b15685d4fad9f43a8452575b44a"
     }
    },
    "d3923d789f044b9dad87827e479971b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d48c3de0acf04ae3979318671f861bf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d86d013fff214d88aa962e0dcc016279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d98563d8614f4bec8a995fc876a9247c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e688e965fd394e2bab2faa90b9841882": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef82c7cfab5f4505b0a8f8e180fce20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f865f94a1890414ba928c8f17c94e9c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90f0ed23dd9049a2bf36bed9e5344226",
      "placeholder": "​",
      "style": "IPY_MODEL_d3923d789f044b9dad87827e479971b5",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
